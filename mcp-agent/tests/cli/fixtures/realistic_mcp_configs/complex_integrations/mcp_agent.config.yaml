$schema: ../../../../../../mcp-agent/schema/mcp-agent.config.schema.json

execution_engine: asyncio
logger:
  transports: [console, file]
  level: debug
  progress_display: true
  path_settings:
    path_pattern: "logs/mcp-agent-{unique_id}.jsonl"
    unique_id: "timestamp"
    timestamp_format: "%Y%m%d_%H%M%S"

mcp:
  servers:
    fetch:
      command: "uvx"
      args: ["mcp-server-fetch"]
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem"]

# Model provider settings (non-sensitive)
openai:
  default_model: "gpt-4o"
  max_tokens: 4000
  temperature: 0.7

anthropic:
  default_model: "claude-3-opus-20240229"
  max_tokens: 4000
  temperature: 0.7

google:
  default_model: "gemini-2.0-flash"

bedrock:
  default_model: "anthropic.claude-3-haiku-20240307-v1:0"
  
# Database configuration (non-sensitive)
database:
  host: localhost
  port: 5432
  database: mcp_agent_db
  ssl: true

# Vector database settings
vector_db:
  host: localhost
  port: 6333
  collection: embeddings